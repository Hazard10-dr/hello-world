{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNdAW3s4h-DZ",
        "outputId": "db0d5b46-86ff-44a0-b1f3-86eb94d75cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/142.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/101.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q otter-grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n0x2S9Oh-Db",
        "outputId": "774162d8-8537-499c-e223-fc6de5145362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tests'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 33 (delta 26), reused 12 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (33/33), 15.24 KiB | 3.81 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !git clone https://github.com/porrashuang/CSE6740_CDA_HW1_Tests.git tests\n",
        "else:\n",
        "    print(\"Not running in Colab\")\n",
        "\n",
        "import otter\n",
        "grader = otter.Notebook()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VihcSwPh-Dc"
      },
      "source": [
        "# Task 1: K-Means Clustering (20 pts)\n",
        "\n",
        "## Goal\n",
        "Implement a complete K-means clustering algorithm from scratch and test it on real data.\n",
        "\n",
        "### Core Functions\n",
        "1. **Distance calculation** - Compute Euclidean distance between points\n",
        "2. **Find nearest centroid** - Determine which centroid is closest to a given point  \n",
        "3. **Update assignments** - Assign all data points to their nearest centroids\n",
        "4. **Update centroids** - Recalculate centroid positions based on assigned points\n",
        "5. **Full K-means algorithm** - Combine everything with proper initialization and convergence\n",
        "\n",
        "### Testing\n",
        "Your implementation will be tested on the digits dataset to see how well it can identify different digit clusters compared to random guessing.\n",
        "\n",
        "## Evaluation\n",
        "- All functions work correctly and pass unit tests\n",
        "- K-means achieves better clustering than random assignment on MNIST dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J6bo9tdah-Df",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def distance_euclidean(a, b):\n",
        "    \"\"\"Compute the Euclidean distance between two points a and b.\n",
        "    Input: a, b: numpy arrays of shape (d,)\n",
        "    Output: Euclidean distance between a and b.\n",
        "    \"\"\"\n",
        "    return np.linalg.norm(a - b, 2)\n",
        "    ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BU44A2yz7QJa",
        "outputId": "26d78e27-4021-4f6d-fea9-44a57cefc2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "distance_euclidean results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>distance_euclidean</pre></strong> passed! üôå</p>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "grader.check(\"distance_euclidean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NzD6s2jVh-Dj",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def find_closest_centroid(x, centroids):\n",
        "    \"\"\"Find the index of the closest centroid to point x.\n",
        "    Input: x: numpy array of shape (d,)\n",
        "           centroids: numpy array of shape (k, d) where each row is a centroid\n",
        "    Output: index of the closest centroid to x.\n",
        "    \"\"\"\n",
        "    distances = np.linalg.norm(centroids - x, axis=1)\n",
        "    return np.argmin(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "sPS0dlcH7QJa",
        "outputId": "dd70ac8b-5f12-412d-f1bc-5c89ed83b4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "find_closest_centroid results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>find_closest_centroid</pre></strong> passed! üåà</p>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "grader.check(\"find_closest_centroid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J1QUJ3Tah-Dl",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def update_assignments(X, centroids):\n",
        "       \"\"\"Update the cluster assignments for each point in X.\n",
        "       Input: X: numpy array of shape (n, d)\n",
        "                 centroids: numpy array of shape (k, d)\n",
        "       Output: numpy array of shape (n,) containing the index of the closest centroid for each point\n",
        "       \"\"\"\n",
        "       distances = np.linalg.norm(centroids[:, np.newaxis] - X, axis=2)\n",
        "       return np.argmin(distances, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zWKEmAoV7QJa",
        "outputId": "01708fa4-eeec-4828-a66b-58a41ab0defa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_assignments results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>update_assignments</pre></strong> passed! üíØ</p>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "grader.check(\"update_assignments\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZlHtK4z2h-Dn",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def update_centroids(X, assignments):\n",
        "    \"\"\"\n",
        "    Update centroids by computing the mean of all points assigned to each centroid.\n",
        "    Input:\n",
        "        X: numpy array of shape (n, d)\n",
        "        assignments: numpy array of shape (n,) with cluster indices (0..k-1)\n",
        "\n",
        "    ***** Note *******\n",
        "    In order to make the result deterministic, initialize centroids with zeros.\n",
        "    For centroids with no assignment, remove them.\n",
        "    **** End Note ****\n",
        "\n",
        "    Output:\n",
        "        centroids: numpy array of shape (k, d)\n",
        "    \"\"\"\n",
        "    unique_clusters = np.unique(assignments)\n",
        "    centroids = np.zeros((len(unique_clusters), X.shape[1]))\n",
        "\n",
        "    for i in range(len(unique_clusters)):\n",
        "      centroids[i] = np.mean(X[assignments == unique_clusters[i]], axis=0)\n",
        "    return centroids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-GvLFMIz7QJb",
        "outputId": "d56623c4-61ba-4bae-f448-7a50897ec1df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_centroids results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>update_centroids</pre></strong> passed! üôå</p>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "grader.check(\"update_centroids\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "p1hE0Evc7QJb"
      },
      "source": [
        "\n",
        "The evaluation process for K-means clustering on MNIST digits dataset follows these key steps:\n",
        "\n",
        "### 1. Data Loading & Preprocessing\n",
        "We will load the digits dataset (8x8 images of handwritten digits 0-9) from sklearn.datasets. We will split into training (70%) and test (30%) sets. We will use the training set to learn cluster centroids.\n",
        "\n",
        "### 2. K-means Clustering\n",
        "Run `myKmeans` on training data with k=10 clusters (one for each digit) and get the final centroids and assignments.\n",
        "\n",
        "### 3. Cluster-to-Label Mapping\n",
        "We use Hungarian algorithm https://en.wikipedia.org/wiki/Hungarian_algorithm to optimally map clusters to digit labels. In short, it tries to match the cluster assignments to the true labels by building a cost matrix based on how well each cluster represents each digit.\n",
        "\n",
        "### 4. Test Set Prediction\n",
        "We will assign test points to the nearest centroids using `update_assignments()`. Then, we will map the cluster assignments to digit labels using the mapping from step 3.\n",
        "\n",
        "### 5. Performance Evaluation\n",
        "The evaluation is done by calculating Adjusted Rand Index (ARI) between predicted and true labels and comparing against random baseline (random digit assignment). As long as the K-means ARI must exceed random ARI by 0.3, we consider it a success. The private test has the same structure but different random seed.\n",
        "\n",
        "### 6. Visualization\n",
        "At the end, we will display the 10 centroids as 8x8 images to see what each cluster learned\n",
        "\n",
        "The evaluation shows that K-means should discover meaningful digit patterns and significantly outperform random guessing at clustering similar digits together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gS6YhzLah-Dq",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def myKmeans(X, k, init_centroids=None, max_iters=100, epsilon=1e-4):\n",
        "    \"\"\"\n",
        "    K-means clustering algorithm.\n",
        "\n",
        "    Input:\n",
        "        X (np.ndarray): data points, shape (n, d)\n",
        "        k (int): number of clusters\n",
        "        init_centroids (np.ndarray, optional): initial centroids, shape (k, d)\n",
        "        max_iters (int): maximum number of iterations\n",
        "        epsilon (float): convergence threshold\n",
        "\n",
        "    Output:\n",
        "        tuple: centroids (np.ndarray of shape (k, d)), assignments of each data point (np.ndarray of shape (n,))\n",
        "    \"\"\"\n",
        "    # Initialize centroids randomly from the training data\n",
        "    if init_centroids is not None:\n",
        "        centroids = init_centroids\n",
        "    else:\n",
        "        indices = np.random.choice(X.shape[0], k, replace=False)\n",
        "        centroids = X[indices].copy()\n",
        "\n",
        "    for num in range(max_iters):\n",
        "      distances = np.linalg.norm(centroids[:, np.newaxis] - X, axis=2)\n",
        "      assignments = np.argmin(distances, axis=0)\n",
        "      unique_clusters = np.unique(assignments)\n",
        "\n",
        "      for i in range(len(unique_clusters)):\n",
        "        centroids[i] = np.mean(X[assignments == unique_clusters[i]], axis=0)\n",
        "    return (centroids, assignments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "GaBLkC2d7QJb"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "def test_MNIST():\n",
        "    # Load the digits dataset (acts as the MNIST dataset for demonstration)\n",
        "    X, y = load_digits(return_X_y=True)\n",
        "\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "    # Number of clusters (10 digits)\n",
        "    k = len(np.unique(y_train))\n",
        "\n",
        "\n",
        "    centroids, assignments = myKmeans(X_train, k)\n",
        "    # Map cluster indices to actual digit labels using the Hungarian algorithm\n",
        "    train_pred_clusters = assignments\n",
        "    cost_matrix = np.zeros((k, k))\n",
        "    for i in range(k):\n",
        "        for j in range(k):\n",
        "            mask = train_pred_clusters == i\n",
        "            cost_matrix[i, j] = -np.sum(y_train[mask] == j)\n",
        "\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "    cluster_to_label = {row: col for row, col in zip(row_ind, col_ind)}\n",
        "\n",
        "    # Predict labels for the test data\n",
        "    # Assign each test point to the nearest centroid\n",
        "    test_pred_clusters = update_assignments(X_test, centroids)\n",
        "    test_pred_labels = np.array([cluster_to_label[c] for c in test_pred_clusters])\n",
        "\n",
        "    # Compute the Adjusted Rand Index (ARI) for the K-means predictions\n",
        "    ari_score = adjusted_rand_score(y_test, test_pred_labels)\n",
        "\n",
        "    # Baseline comparison: Random guess for each test label\n",
        "    random_pred_labels = np.random.choice(np.unique(y_train), size=len(y_test))\n",
        "    ari_score_random = adjusted_rand_score(y_test, random_pred_labels)\n",
        "\n",
        "    return ari_score, ari_score_random, centroids, cluster_to_label\n",
        "ari_score, ari_score_random, centroids, cluster_to_label = test_MNIST()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dp25JQ_a7QJb",
        "outputId": "acfb9843-6a8b-4632-c02c-462c3ad9e4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "kmeans results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>kmeans</pre></strong> passed! üåü</p>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "grader.check(\"kmeans\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UmSnKV9x7QJb"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "MLev26087QJb",
        "outputId": "c9e57730-7647-40fa-c01d-3205b38f6aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the centroids as 8x8 digit images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(10):\n",
        "    # Reshape centroid back to 8x8 image\n",
        "    centroid_image = centroids[i].reshape(8, 8)\n",
        "    axes[i].imshow(centroid_image, cmap='gray')\n",
        "    # Show which digit this centroid represents\n",
        "    assigned_digit = cluster_to_label.get(i, '?')\n",
        "    axes[i].set_title(f'Cluster {i} to Digit {assigned_digit}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('K-means Centroids as Digit Images', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "sPvDDHdJ7QJb"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "## What other ways we can initialize centroids? List at least 2 and their advantages/disadvantages. [1.5 pts]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "XPyP0Bw_7QJb"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. You can select k number of points out of the datasets as the centroids. The advantge of this is that it prevents centroids from being placed where no data exists\n",
        "\n",
        "2. You can also assume that all the dataset is a cluster such that you have the same number of datasets as cluster. Although the accuracy might be high but it would be very computationally expensive because if the number of dataset is very high the number of cluster would be high too and this would cause overfitting as well."
      ],
      "metadata": {
        "id": "FN0l0qrbvk5q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cyhlkC_6h-Du"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "# Task 2: Three Coins Model (30 pts)\n",
        "\n",
        "### Purpose\n",
        "- Develop an intuitive understanding of the EM algorithm using a simple example.  \n",
        "- Implement a basic EM algorithm to solve the three coins problem.\n",
        "\n",
        "### Problem Statement\n",
        "Consider three coins **A**, **B**, and **C**, with probabilities of landing heads denoted as $p_0$, $p_1$, and $p_2$, respectively.  \n",
        "\n",
        "The process is as follows:\n",
        "1. Flip coin **A**.  \n",
        "   - If **A** shows heads, flip coin **B**.  \n",
        "   - If **A** shows tails, flip coin **C**.  \n",
        "2. Record the outcome of the second flip as $y_i$, where:  \n",
        "   - $y_i = 1$ if the result is heads.  \n",
        "   - $y_i = 0$ if the result is tails.  \n",
        "\n",
        "Given a sequence of observed outcomes $y_0, y_1, \\dots, y_n$, the task is to estimate the parameters $p_0$, $p_1$, and $p_2$ using the Expectation-Maximization (EM) algorithm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "A8r3GvbGh-D1"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "# Complete Data Log-Likelihood Function\n",
        "\n",
        "Let's simplify the problem by assuming that the outcome of the first coin flip is known and denoted as $z_i$, where:\n",
        "\n",
        "- $z_i = 1$ if coin $B$ was used,  \n",
        "- $z_i = 0$ if coin $C$ was used.  \n",
        "\n",
        "Given $z_i$ and the observed data $y_i$, can you define the log-likelihood function $L(z_i, y_i, p_0, p_1, p_2) = \\log P(z_i, y_i \\mid p_0, p_1, p_2)$ and implement it? [Writing is optional and won't be graded, but coding has points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "UYWwgYm17QJb"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ODry4OHH7QJb"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MP9xoCOJh-D2",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def compute_log_likelihood(y_i, z_i, p_0, p_1, p_2):\n",
        "    \"\"\"\n",
        "    Compute complete-data log-likelihood for one trial.\n",
        "\n",
        "    Input:\n",
        "        y_i (int): observed result of the second toss, 1=heads, 0=tails\n",
        "        z_i (int): latent branch,\n",
        "                   1 if coin A=H -> coin B,\n",
        "                   0 if coin A=T -> coin C\n",
        "        p_0 (float): P(H on coin A)\n",
        "        p_1 (float): P(H on coin B)\n",
        "        p_2 (float): P(H on coin C)\n",
        "\n",
        "    Output:\n",
        "        float: log P(y_i, z_i | parameters)\n",
        "    \"\"\"\n",
        "    if z_i == 1 and y_i == 1:\n",
        "        return np.log(p_0 *p_1)\n",
        "    if z_i == 1 and y_i == 0:\n",
        "        return np.log(p_0 * (1 - p_1))\n",
        "    if z_i == 0 and y_i == 1:\n",
        "        return np.log((1-p_0) * p_2)\n",
        "    if z_i == 0 and y_i == 0:\n",
        "        return np.log((1-p_0) * p_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "NPgZrrwO7QJb",
        "outputId": "2972f31e-63d0-4720-9d6d-677adddc795b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "complete-log-likelihood-coding results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>complete-log-likelihood-coding</pre></strong> passed! üåà</p>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "grader.check(\"complete-log-likelihood-coding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mGeNmzhRh-D4"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "### Write the complete log-likelihood formula for all observations $y_0, y_1, \\dots, y_n$ with corresponding latent variables $z_0, z_1, \\dots, z_n$. [Optional, won't be graded]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "lgUtVJSk7QJb"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$log[\\sum_{i}^{n}\\sum_{i}^{n} p(z_{i}|p_o, p_1, p_2)p(y_{i}|z_{i}, p_o, p_1, p_2)]$"
      ],
      "metadata": {
        "id": "5HebKCSSUxJq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EnT1KAxj7QJc"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "\n",
        "Given the observations $Y = (y_0, y_1, \\dots, y_n)$ and the latent variables $Z = (z_0, z_1, \\dots, z_n)$, how can we maximize the log-likelihood function $L(Y, Z, p_0, p_1, p_2)$ with respect to the parameters $p_0$, $p_1$, and $p_2$? [Optional, won't be graded]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "X8Wo1pRq7QJc"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\theta_{ml} = argmax_{\\theta = p_o, p_1, p_2} L(\\theta)$<br>\n",
        "$\\theta_{ml} = argmax_{\\theta = p_o, p_1, p_2} log[\\sum_{i}^{n}\\sum_{i}^{n} p(z_{i}|p_o, p_1, p_2)p(y_{i}|z_{i}, p_o, p_1, p_2)]$<br>\n",
        "$\\theta_{ml} = \\frac{\\partial L(\\theta)}{\\partial (\\theta)}$"
      ],
      "metadata": {
        "id": "h4bG3ChRU_21"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "t86d8pZKh-D4"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "## Incomplete Data Log-Likelihood - Posterior of $z_i$\n",
        "Now, let's assume that you do not know the result of the first coin $z_i$. Although you do not know the first coin result, you can still 'guess' by computing the posterior probability of $z_i$ given the observed data $y_i$ and the parameters $p_0, p_1, p_2$. From now on, we will use $\\theta = (p_0, p_1, p_2)$ to denote the parameters of the model.\n",
        "\n",
        "Let's note the latent variable as $z_i$ where $z_i = 1$ if the coin $B$ was used and $z_i = 0$ if the coin $C$ was used. We can estimate the latent variable $z_i$ given the observed data $y_i$.\n",
        "\n",
        "\n",
        " What is the posterior probability $P(z_i = 1 | y_i, \\theta)$? Can you write it mathematically and implement it? [Writing is optional and won't be graded, but coding has points]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "iz2YrNG77QJc"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$p(z_{i}=1|y_{i}, \\theta) = \\frac{p(z_{i}=1|y_{i}, \\theta)}{p(y_{i}|\\theta)}$<br>\n",
        "$p(z_{i}=1|y_{i}, \\theta) = \\frac{p_0 * p_1}{p_0 * p_1 + (1 - p_0)*p_2}$\n"
      ],
      "metadata": {
        "id": "XBDSMLbeg4TH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "CV44YXeg7QJc"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NON4pv0Qh-D5",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def compute_posterior(y_i, p_0, p_1, p_2):\n",
        "    \"\"\"\n",
        "    Compute the posterior probability P(z_i = 1 | y_i, theta)\n",
        "    Input: y_i (observation), p_0 (prior for coin A), p_1 (likelihood for coin B), p_2 (likelihood for coin C)\n",
        "    Output: Posterior probability P(z_i = 1 | y_i, theta)\n",
        "    \"\"\"\n",
        "    numerator = p_0 * p_1\n",
        "    denominator = (p_0 * p_1) + (1 - p_0)* (p_2)\n",
        "    return numerator / denominator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ZAs1DhQS7QJc",
        "outputId": "94f5b188-d551-48cb-8eae-7ed508f4d229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "posterior-of-z_i-coding results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>posterior-of-z_i-coding</pre></strong> passed! üåü</p>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "grader.check(\"posterior-of-z_i-coding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "lkqPUTbGh-D7",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "What is the posterior probability $P(z_i = 0 | y_i, \\theta)$?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$p(z_{i}=0|y_{i}, \\theta) = \\frac{p(z_{i}=0|y_{i}, \\theta)}{p(y_{i}|\\theta)}$<br>\n",
        "$p(z_{i}=0|y_{i}, \\theta) = \\frac{(1 - p_0) * p_2}{p_0 * p_1 + (1 - p_0)*p_2}$\n"
      ],
      "metadata": {
        "id": "cusC3K5QiMQC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tdOhM5eth-D7",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def compute_posterior_zero(y_i, p_0, p_1, p_2):\n",
        "    \"\"\"\n",
        "    Compute the posterior probability P(z_i = 0 | y_i, \\theta)\n",
        "    Input: y_i (observation), p_0 (prior for coin A), p_1 (likelihood for coin B), p_2 (likelihood for coin C)\n",
        "    Output: Posterior probability P(z_i = 0 | y_i, \\theta)\n",
        "    \"\"\"\n",
        "    numerator = (1- p_0) * p_2\n",
        "    denominator = (p_0 * p_1) + (1 - p_0)* (p_2)\n",
        "    return numerator / denominator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "avxBrPHj7QJc",
        "outputId": "fd896123-e2c5-4a22-d1fc-eab5f04b98ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "posterior-of-z_i-coding-zero results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>posterior-of-z_i-coding-zero</pre></strong> passed! üôå</p>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "grader.check(\"posterior-of-z_i-coding-zero\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHBF8EmFh-D_",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "Since we do not know $z$, but from Jensen Inequality we learned in class, we can lower bound the euqation. Thus we use the posterior probability of $z$ under the current parameters to estimate the log-likelihood function. This is called the Q-function in the EM algorithm. The Q-function is defined as follows:\n",
        "```math\n",
        "Q(\\theta | \\theta_k) = \\mathbb{E}_{z \\sim P(z | y, \\theta_k)} [\\log P(y, z | \\theta)]\n",
        "```\n",
        "Note that $\\theta_k$ is the current parameter and $\\theta$ is the new parameter we want to maxmize the log-likelihood for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "l6364_kbh-D_",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### E-step\n",
        "Calculate the log-likelihood function $Q(p_0, p_1, p_2 | p_0^{(t)}, p_1^{(t)}, p_2^{(t)})$ using the posterior probability of $z_i$ under the current parameters $p_0^{(t)}, p_1^{(t)}, p_2^{(t)}$. The return should be log-likelihood of $p_0, p_1, p_2$ given the current parameters $p_0^{(t)}, p_1^{(t)}, p_2^{(t)}$ and observations $Y = (y_0, y_1, ..., y_n)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1GWmZITRh-EX",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def Q_function(Y, p_0, p_1, p_2, p_0_t, p_1_t, p_2_t):\n",
        "    \"\"\"\n",
        "    Compute the Q-function for the EM algorithm.\n",
        "\n",
        "    Input:\n",
        "        Y (list of int): observed results of the second toss, 1=heads, 0=tails\n",
        "        p_0 (float): current estimate of P(H on coin A)\n",
        "        p_1 (float): current estimate of P(H on coin B)\n",
        "        p_2 (float): current estimate of P(H on coin C)\n",
        "        p_0_t (float): previous estimate of P(H on coin A)\n",
        "        p_1_t (float): previous estimate of P(H on coin B)\n",
        "        p_2_t (float): previous estimate of P(H on coin C)\n",
        "\n",
        "    Output:\n",
        "        float: Q(p_0, p_1, p_2 | p_0_t, p_1_t, p_2_t)\n",
        "    \"\"\"\n",
        "    Q_val = 0.0\n",
        "\n",
        "    for y in Y:\n",
        "        # Posterior for y == 1 (A->B given head)\n",
        "        denom_head = (p_0_t * p_1_t) + ((1 - p_0_t) * p_2_t)\n",
        "        gamma_head = (p_0_t * p_1_t) / (denom_head)\n",
        "\n",
        "        # Posterior for y == 0 (A->B given tail)\n",
        "        denom_tail = (p_0_t * (1 - p_1_t)) + ((1 - p_0_t) * (1 - p_2_t))\n",
        "        gamma_tail = (p_0_t * (1 - p_1_t)) / (denom_tail)\n",
        "\n",
        "        if y == 1:\n",
        "            Q_val += gamma_head * np.log((p_0 * p_1))\n",
        "            Q_val += (1 - gamma_head) * np.log(((1 - p_0) * p_2))\n",
        "        else:  # y == 0\n",
        "            Q_val += gamma_tail * np.log((p_0 * (1 - p_1)))\n",
        "            Q_val += (1 - gamma_tail) * np.log(((1 - p_0) * (1 - p_2)))\n",
        "\n",
        "    return Q_val\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = [1, 0, 1]\n",
        "p0, p1, p2 = (0.5, 0.7, 0.4)\n",
        "p0_t, p1_t, p2_t = (0.6, 0.8, 0.2)\n",
        "expected = -3.652547418589841\n",
        "\n",
        "print(Q_function(Y, p0, p1, p2, p0_t, p1_t, p2_t))\n",
        "# ‚Üí -3.652547418589841\n"
      ],
      "metadata": {
        "id": "FB4XwimmUBhz",
        "outputId": "26346a47-06b3-4460-b7ee-02d03ccc37ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3.6525474186004105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XduIbnvb7QJf",
        "outputId": "b9a8241c-ad3e-4190-99fd-0a3c8f308d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "q-function results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>q-function</pre></strong> passed! ‚ú®</p>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "grader.check(\"q-function\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "RQMjbFQSh-EZ",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# M-Step\n",
        "Maximize the Q-function $Q(p_0, p_1, p_2 | p_0^{(t)}, p_1^{(t)}, p_2^{(t)})$ with respect to the parameters $p_0$, $p_1$, and $p_2$. The return should be the new parameters $p_0^{(t+1)}$, $p_1^{(t+1)}$, and $p_2^{(t+1)}$ that maximize the Q-function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def update_parameters(Y, p_0, p_1, p_2):\n",
        "    \"\"\"\n",
        "    Update the parameters of the model using EM.\n",
        "    Input:\n",
        "        Y (list of int): observed coin tosses (1=heads, 0=tails)\n",
        "        p_0, p_1, p_2: current estimates\n",
        "    Output:\n",
        "        Updated parameters (p_0_new, p_1_new, p_2_new)\n",
        "    \"\"\"\n",
        "    #N = len(Y)\n",
        "\n",
        "    # responsibilities\n",
        "    gamma_A = []  # P(Z=A | y)\n",
        "    gamma_notA = []  # P(Z‚â†A | y)\n",
        "\n",
        "    for y in Y:\n",
        "        if y == 1:  # heads\n",
        "            denom = (p_0 * p_1) + ((1 - p_0) * p_2)\n",
        "            gA = (p_0 * p_1) / denom\n",
        "        else:  # tails\n",
        "            denom = (p_0 * (1 - p_1)) + ((1 - p_0) * (1 - p_2))\n",
        "            gA = (p_0 * (1 - p_1)) / denom\n",
        "\n",
        "        gamma_A.append(gA)\n",
        "        gamma_notA.append(1 - gA)\n",
        "\n",
        "    gamma_A = np.array(gamma_A)\n",
        "    gamma_notA = np.array(gamma_notA)\n",
        "    Y = np.array(Y)\n",
        "\n",
        "    # M-step updates\n",
        "    p_0_new = np.mean(gamma_A)\n",
        "    p_1_new = np.sum(gamma_A * Y) / np.sum(gamma_A)\n",
        "    p_2_new = np.sum(gamma_notA * Y) / np.sum(gamma_notA)\n",
        "\n",
        "    return p_0_new, p_1_new, p_2_new\n"
      ],
      "metadata": {
        "id": "z--ZODWjvKRQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_parameters(Y, tol=1e-6, max_iter=1000):\n",
        "    # Initialize randomly\n",
        "    p_0, p_1, p_2 = random.random(), random.random(), random.random()\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        p_0_new, p_1_new, p_2_new = update_parameters(Y, p_0, p_1, p_2)\n",
        "\n",
        "        # check convergence\n",
        "        if (abs(p_0_new - p_0) < tol and\n",
        "            abs(p_1_new - p_1) < tol and\n",
        "            abs(p_2_new - p_2) < tol):\n",
        "            break\n",
        "\n",
        "        p_0, p_1, p_2 = p_0_new, p_1_new, p_2_new\n",
        "\n",
        "    return p_0, p_1, p_2"
      ],
      "metadata": {
        "id": "I0IEF282vYhy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HsFeaj-Ph-Ea",
        "outputId": "59d200ad-ca94-4976-d52d-f4008351a42f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True parameters: p_0=0.5, p_1=0.7, p_2=0.4\n",
            "Estimated parameters: p_0=0.5289, p_1=0.9943, p_2=0.0576\n",
            "Is it a good estimation?\n"
          ]
        }
      ],
      "source": [
        "def generate_test(p_0, p_1, p_2, n=100):\n",
        "    \"\"\"\n",
        "    Generate a test dataset based on the given parameters.\n",
        "\n",
        "    Input:\n",
        "        p_0 (float): P(H on coin A)\n",
        "        p_1 (float): P(H on coin B)\n",
        "        p_2 (float): P(H on coin C)\n",
        "        n (int): number of trials\n",
        "\n",
        "    Output:\n",
        "        list of int: generated observed results of the second toss\n",
        "    \"\"\"\n",
        "    Y = []\n",
        "    for _ in range(n):\n",
        "        z_i = 1 if random.random() < p_0 else 0\n",
        "        y_i = 1 if random.random() < (p_1 if z_i == 1 else p_2) else 0\n",
        "        Y.append(y_i)\n",
        "    return Y\n",
        "p_0, p_1, p_2 = 0.5, 0.7, 0.4\n",
        "Y_0 = generate_test(p_0, p_1, p_2, n=1000)\n",
        "p_estimated_0, p_estimated_1, p_estimated_2 = estimate_parameters(Y_0)\n",
        "print(f\"True parameters: p_0={p_0}, p_1={p_1}, p_2={p_2}\")\n",
        "print(f\"Estimated parameters: p_0={p_estimated_0:.4f}, p_1={p_estimated_1:.4f}, p_2={p_estimated_2:.4f}\")\n",
        "print(\"Is it a good estimation?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "eoxNfH0S7QJf",
        "outputId": "ddde241a-ded1-4eda-e437-23e69b1a2c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "m-step results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>m-step</pre></strong> passed! ‚ú®</p>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "grader.check(\"m-step\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ZVUCN_rWh-Ea"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "# Modified Problem: 5 Flips Per Trial\n",
        "\n",
        "In the modified version:\n",
        "1. Flip coin A once\n",
        "2. If A shows heads -> flip coin B **5 times**\n",
        "3. If A shows tails -> flip coin C **5 times**\n",
        "4. Record all 5 outcomes as a sequence: e.g., `[1, 0, 1, 1, 0]`\n",
        "\n",
        "Now each observation `y_i` is a list of 5 outcomes instead of a single outcome. We again simply and assume we now latent variables `z_i` for each sequence of flips.\n",
        "What is the complete data log-likelihood for a sequence of flips with parameter $\\theta$? [Writing is optional and won't be graded, but coding has points]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "hu_DdfJn7QJf"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "226feWJQ7QJf"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LG7nyciBh-Ea",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def compute_log_likelihood_sequence(y_sequence, z_i, p_0, p_1, p_2):\n",
        "    \"\"\"\n",
        "    Compute complete-data log-likelihood for a sequence of flips.\n",
        "\n",
        "    Input:\n",
        "        y_sequence (list): sequence of flip results, e.g., [1, 0, 1, 1, 0]\n",
        "        z_i (int): latent branch, 1 if coin B, 0 if coin C\n",
        "        p_0 (float): P(H on coin A)\n",
        "        p_1 (float): P(H on coin B)\n",
        "        p_2 (float): P(H on coin C)\n",
        "\n",
        "    Output:\n",
        "        float: log P(y_sequence, z_i | parameters)\n",
        "    \"\"\"\n",
        "    count_ones  = y_sequence.count(1)\n",
        "    count_zeros = y_sequence.count(0)\n",
        "    if z_i == 1:\n",
        "        return np.log(p_0 *(p_1**(count_ones) * (1 - p_1)**(count_zeros)))\n",
        "    if z_i == 0:\n",
        "        return np.log((1 - p_0) * (p_2**(count_ones) * (1 - p_2)**(count_zeros)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Drvas29R7QJf",
        "outputId": "2e56ed97-f891-4874-f84d-b2a255b24183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "log-likelihood-sequence results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>log-likelihood-sequence</pre></strong> passed! üíØ</p>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "grader.check(\"log-likelihood-sequence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Nvrcxi7QJf"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNv-2_Nw7QJf"
      },
      "source": [
        "## Incomplete Data Log-Likelihood - Posterior of $z_i$\n",
        "Again, let's assume that you do not know the result of the first coin $z_i$.\n",
        " What is the posterior probability $P(z_i = 1 | y_i, \\theta)$? Can you write it mathematically and implement it? [Writing is optional and won't be graded, but coding has points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Jwi4nqdX7QJf"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uhLPybJ8h-Ei",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def compute_posterior_sequence(y_sequence, p_0, p_1, p_2):\n",
        "    \"\"\"\n",
        "    Compute P(z_i = 1 | y_sequence) for a sequence of flips.\n",
        "\n",
        "    Input:\n",
        "        y_sequence (list): sequence of flip results\n",
        "        p_0, p_1, p_2: current parameter estimates\n",
        "\n",
        "    Output:\n",
        "        float: P(z_i = 1 | y_sequence)\n",
        "    \"\"\"\n",
        "    count_ones  = y_sequence.count(1)\n",
        "    count_zeros = y_sequence.count(0)\n",
        "    numerator = (p_0 *(p_1**(count_ones) * (1 - p_1)**(count_zeros)))\n",
        "    denominator = (p_0 *(p_1**(count_ones) * (1 - p_1)**(count_zeros))) + ((1 - p_0) * (p_2**(count_ones) * (1 - p_2)**(count_zeros)))\n",
        "    return numerator / denominator\n",
        "\n",
        "def compute_posterior_zero_sequence(y_sequence, p_0, p_1, p_2):\n",
        "    \"\"\"\n",
        "    Compute P(z_i = 0 | y_sequence) for a sequence of flips.\n",
        "    \"\"\"\n",
        "    count_ones  = y_sequence.count(1)\n",
        "    count_zeros = y_sequence.count(0)\n",
        "    numerator = ((1 - p_0) * (p_2**(count_ones) * (1 - p_2)**(count_zeros)))\n",
        "    denominator = (p_0 *(p_1**(count_ones) * (1 - p_1)**(count_zeros))) + ((1 - p_0) * (p_2**(count_ones) * (1 - p_2)**(count_zeros)))\n",
        "    return numerator / denominator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HD-EF69k7QJf",
        "outputId": "2cdb19c2-7861-468d-ce24-aca9e086e95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "posterior-sequence-coding results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>posterior-sequence-coding</pre></strong> passed! üôå</p>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "grader.check(\"posterior-sequence-coding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "PRm7WkBV7QJf"
      },
      "source": [
        "### E-step\n",
        "Calculate the log-likelihood function but this time Y is a list of sequences, $Y = [[y_{0,0}, y_{0,1}, \\ldots, y_{0,T_0}], [y_{1,0}, y_{1,1}, \\ldots, y_{1,T_1}], \\ldots, [y_{N,0}, y_{N,1}, \\ldots, y_{N,T_N}]]$. The return should be log-likelihood of $p_0, p_1, p_2$ given the current parameters $p_0^{(t)}, p_1^{(t)}, p_2^{(t)}$ and observations $Y = (y_0, y_1, ..., y_n)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-yZu7VRVh-El",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def Q_function_sequence(Y_sequences, p_0, p_1, p_2, p_0_t, p_1_t, p_2_t):\n",
        "    \"\"\"\n",
        "    Compute the Q-function for sequences.\n",
        "\n",
        "    Input:\n",
        "        Y_sequences (list of lists): Each element is a sequence of 5 flips\n",
        "        p_0, p_1, p_2: current parameters to evaluate\n",
        "        p_0_t, p_1_t, p_2_t: previous iteration parameters for posterior computation\n",
        "\n",
        "    Output:\n",
        "        float: Q-function value\n",
        "    \"\"\"\n",
        "    Q_val = 0.0\n",
        "\n",
        "    for y_sequence in Y_sequences:\n",
        "      count_ones  = y_sequence.count(1)\n",
        "      count_zeros = y_sequence.count(0)\n",
        "\n",
        "      # Posterior for y == 1 (A->B given head)\n",
        "      denom_head = (p_0_t * (p_1_t**(count_ones)) * ((1 - p_1_t)**count_zeros)) + ((1 - p_0_t) * ((p_2_t)**(count_ones)) * ((1 - p_2_t)**(count_zeros)))\n",
        "      gamma_head = (p_0_t * (p_1_t**(count_ones)) * ((1 - p_1_t)**(count_zeros))) / (denom_head)\n",
        "\n",
        "      # Posterior for y == 0 (A->B given tail)\n",
        "      denom_tail = (p_0_t * (p_1_t**(count_ones)) * ((1 - p_1_t)**count_zeros)) + ((1 - p_0_t) * ((p_2_t)**(count_ones)) * ((1 - p_2_t)**(count_zeros)))\n",
        "      gamma_tail = (p_0_t * (p_1_t**(count_ones)) * (1 - p_1_t)**(count_zeros)) / (denom_tail)\n",
        "\n",
        "      if y_sequence == 1:\n",
        "        Q_val += gamma_head * np.log((p_0 * (p_1**(count_ones)) * ((1 - p_1)**(count_zeros))))\n",
        "        Q_val += (1 - gamma_head) * np.log(((1 - p_0) * p_2**(count_ones) * (1 - p_2)**(count_zeros)))\n",
        "      else:  # y == 0\n",
        "        Q_val += gamma_tail * np.log((p_0 * p_1**(count_ones)*(1 - p_1)**(count_zeros)))\n",
        "        Q_val += (1 - gamma_tail) * np.log(((1 - p_0) * (p_2**(count_ones)) * ((1 - p_2)**(count_zeros))))\n",
        "\n",
        "    return Q_val\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_sequences = [[1, 0, 1, 1, 0], [0, 0, 0, 1, 1]]\n",
        "p_0, p_1, p_2 = (0.5, 0.7, 0.3)\n",
        "p_0_t, p_1_t, p_2_t = (0.4, 0.6, 0.2)\n",
        "Q_function_sequence(Y_sequences, p_0, p_1, p_2, p_0_t, p_1_t, p_2_t)"
      ],
      "metadata": {
        "id": "EFK5-i1XXf4h",
        "outputId": "12445902-9b82-4357-8a13-f42870af95ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(-8.859417052941724)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "tieb7Tml7QJf",
        "outputId": "c8bbd3a2-e931-4e73-8403-5cf0e43aa9af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "q-function-sequence results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>q-function-sequence</pre></strong> passed! üåà</p>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "grader.check(\"q-function-sequence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCAVi0fL7QJg"
      },
      "source": [
        "# M-Step\n",
        "Similarly, maximize the Q-function for sequences, $Q(p_0, p_1, p_2 | p_0^{(t)}, p_1^{(t)}, p_2^{(t)})$, with respect to the parameters $p_0$, $p_1$, and $p_2$. The return should be the new parameters $p_0^{(t+1)}$, $p_1^{(t+1)}$, and $p_2^{(t+1)}$ that maximize the Q-function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KzU2rKzkh-Eo",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def update_parameters_sequence(Y_sequences, p_0, p_1, p_2):\n",
        "    \"\"\"\n",
        "    M-step: Update parameters for sequence data.\n",
        "\n",
        "    Input:\n",
        "        Y_sequences (list of lists): Each element is a sequence of 5 flips\n",
        "        p_0, p_1, p_2: current parameter estimates\n",
        "\n",
        "    Output:\n",
        "        tuple: (p_0_new, p_1_new, p_2_new)\n",
        "    \"\"\"\n",
        "\n",
        "    gamma_A = []      # responsibilities for coin A\n",
        "    counts_ones = []  # number of heads per sequence\n",
        "    counts_zeros = [] # number of tails per sequence\n",
        "\n",
        "    for y_sequence in Y_sequences:\n",
        "        count_ones  = y_sequence.count(1)\n",
        "        count_zeros = y_sequence.count(0)\n",
        "        counts_ones.append(count_ones)\n",
        "        counts_zeros.append(count_zeros)\n",
        "\n",
        "        denom_head = (p_0 * (p_1**(count_ones)) * ((1 - p_1)**count_zeros)) + ((1 - p_0) * ((p_2)**(count_ones)) * ((1 - p_2)**(count_zeros)))\n",
        "        gA = (p_0 * (p_1**(count_ones)) * ((1 - p_1)**(count_zeros))) / (denom_head)\n",
        "        gamma_A.append(gA)\n",
        "\n",
        "    gamma_A = np.array(gamma_A)\n",
        "    gamma_notA = 1 - gamma_A\n",
        "    counts_ones = np.array(counts_ones)\n",
        "    counts_zeros = np.array(counts_zeros)\n",
        "\n",
        "    # --- M-step updates ---\n",
        "    # Mixture weight\n",
        "    p_0_new = np.mean(gamma_A)\n",
        "\n",
        "    # Probability of head with coin A\n",
        "    p_1_new = np.sum(gamma_A * counts_ones) / np.sum(gamma_A * (counts_ones + counts_zeros))\n",
        "\n",
        "    # Probability of head with coin B\n",
        "    p_2_new = np.sum(gamma_notA * counts_ones) / np.sum(gamma_notA * (counts_ones + counts_zeros))\n",
        "\n",
        "    return p_0_new, p_1_new, p_2_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cfK7d67Q7QJg",
        "outputId": "08df4c5f-df64-475b-f170-5963ce6d368e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update-parameters results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>update-parameters</pre></strong> passed! üåü</p>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "grader.check(\"update-parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "c_rscBMuh-Ep",
        "tags": [
          "otter_answer_cell"
        ]
      },
      "outputs": [],
      "source": [
        "def estimate_parameters_sequence(Y_sequences, tol=1e-6, max_iter=1000):\n",
        "    \"\"\"\n",
        "    Iterate until convergence\n",
        "    Input: Y (list of observed data), tol (tolerance for convergence), max_iter (maximum number of iterations)\n",
        "    Output: Estimated parameters (p_0, p_1, p_2)\n",
        "    \"\"\"\n",
        "    p_0, p_1, p_2 = random.random(), random.random(), random.random()\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        p_0_new, p_1_new, p_2_new = update_parameters_sequence(Y_sequences, p_0, p_1, p_2)\n",
        "\n",
        "        # check convergence\n",
        "        if (abs(p_0_new - p_0) < tol and\n",
        "            abs(p_1_new - p_1) < tol and\n",
        "            abs(p_2_new - p_2) < tol):\n",
        "            break\n",
        "\n",
        "        p_0, p_1, p_2 = p_0_new, p_1_new, p_2_new\n",
        "    return p_0, p_1, p_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0FyOrmJA7QJg",
        "outputId": "bb94a0d4-ac27-4404-d46f-162886621db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the modified algorithm with 5 flips per trial:\n",
            "True parameters: p_0=0.3, p_1=0.8, p_2=0.2\n",
            "Estimated parameters: p_0=0.6922, p_1=0.2077, p_2=0.8246\n",
            "\n",
            "First 5 generated sequences:\n",
            "Trial 1: [1, 0, 0, 0, 0] (total heads: 1)\n",
            "Trial 2: [0, 0, 0, 1, 0] (total heads: 1)\n",
            "Trial 3: [0, 1, 0, 0, 0] (total heads: 1)\n",
            "Trial 4: [0, 0, 0, 1, 0] (total heads: 1)\n",
            "Trial 5: [1, 0, 1, 0, 0] (total heads: 2)\n"
          ]
        }
      ],
      "source": [
        "def generate_test_sequence(p_0, p_1, p_2, n=100, k=5):\n",
        "    \"\"\"\n",
        "    Generate test dataset with sequences.\n",
        "\n",
        "    Input:\n",
        "        p_0, p_1, p_2: true parameters\n",
        "        n: number of trials\n",
        "        k: number of flips per trial (5 in our case)\n",
        "\n",
        "    Output:\n",
        "        list of lists: each inner list is a sequence of k flips\n",
        "    \"\"\"\n",
        "    Y_sequences = []\n",
        "    for _ in range(n):\n",
        "        # Flip coin A\n",
        "        z_i = 1 if random.random() < p_0 else 0\n",
        "\n",
        "        # Flip the selected coin k times\n",
        "        coin_prob = p_1 if z_i == 1 else p_2\n",
        "        sequence = [1 if random.random() < coin_prob else 0 for _ in range(k)]\n",
        "        Y_sequences.append(sequence)\n",
        "\n",
        "    return Y_sequences\n",
        "\n",
        "# Example usage:\n",
        "print(\"Testing the modified algorithm with 5 flips per trial:\")\n",
        "p_0, p_1, p_2 = 0.3, 0.8, 0.2\n",
        "Y_seq_test = generate_test_sequence(p_0, p_1, p_2, n=1000, k=5)\n",
        "p_est_0, p_est_1, p_est_2 = estimate_parameters_sequence(Y_seq_test)\n",
        "print(f\"True parameters: p_0={p_0}, p_1={p_1}, p_2={p_2}\")\n",
        "print(f\"Estimated parameters: p_0={p_est_0:.4f}, p_1={p_est_1:.4f}, p_2={p_est_2:.4f}\")\n",
        "\n",
        "# Show a few example sequences\n",
        "print(f\"\\nFirst 5 generated sequences:\")\n",
        "for i, seq in enumerate(Y_seq_test[:5]):\n",
        "    print(f\"Trial {i+1}: {seq} (total heads: {sum(seq)})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WIk4KKV-7QJg",
        "outputId": "234c5619-105d-41dc-ba66-d0ea6f48c853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "estimate-parameters-sequence results: All test cases passed!"
            ],
            "text/html": [
              "<p><strong><pre style='display: inline;'>estimate-parameters-sequence</pre></strong> passed! üôå</p>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "grader.check(\"estimate-parameters-sequence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "jW4f4mv0h-Eu"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "## What is the difference between the current version (5 flips per trial) and the naive version (1 flip per trial)? Would the new version be better for estimating the parameters? Why or why not? [Required answer 2.5 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "ceZyTjKd7QJg"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference in the current version (5 flips per trial) and the naive version (1 flip per trial) is in the formula of the probabilities. while the 1 flip trial gives about 4 scenarios the 5 flips just gives only 2 scenarios. asides that the probability is raised to real number greater than 1 for the y observation as compared to the 1 flip trial that is just raised to either 0 or 1 since it is flipped 1 time. The 5 flips would be a better estimate because it is less bias than the single/one flip, reduce the variances of the parameter estimates and it allows for faster estimation of the parameter"
      ],
      "metadata": {
        "id": "Qr2lwfUaekeB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "vscode": {
          "languageId": "raw"
        },
        "id": "NxtKIRnV7QJg"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "# Can you think of a case where even with a large number of samples and sequence length, the estimated parameters might not be close to the true parameters? [2.5 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "otter_answer_cell"
        ],
        "id": "C9NAQPVN7QJg"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if a wrong initial guess or estimates of the parameters are used for the iterative step, even with the large samples and sequence it might not be close to the true parameters such that you have a problem where the estimates are stucked in a local minimum. This is because the EM algorithm does not guarantee convergence to a global optimum. Asides from this you can also have cases where the data provided is not informative enough to estimate the parameters of the model or if the wrong probability distribution is assumed for this dataset.\n"
      ],
      "metadata": {
        "id": "eidH_08VjVSq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1_Fq0ebAh-E7",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# References\n",
        "+ Copilot\n",
        "+ https://courses.cs.washington.edu/courses/cse160/23wi/homework/a4/\n",
        "+ https://www.cs.columbia.edu/~mcollins/6864/slides/em1.4up.pdf"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}